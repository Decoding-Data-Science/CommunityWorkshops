{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM2gsEALU/sDgxQvG1qcvU+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Decoding-Data-Science/CommunityWorkshops/blob/main/ai_agents_Cover_letter_to_share_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xqvvAz1h_Ze1"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "api_endpoint = 'https://nubela.co/proxycurl/api/v2/linkedin'\n",
        "linkedin_profile_url = 'https://www.linkedin.com/in/faizalahmed0606/'\n",
        "api_key = 'enter your key'\n",
        "headers = {'Authorization': 'Bearer ' + api_key}\n",
        "\n",
        "response = requests.get(api_endpoint,\n",
        "                        params={'url': linkedin_profile_url,'skills': 'include'},\n",
        "                        headers=headers)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "profile_data = response.json()\n",
        "profile_data"
      ],
      "metadata": {
        "id": "tCK5X297_7HH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b239e85-5b0f-4f16-b414-4352359c737a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'public_identifier': 'faizalahmed0606',\n",
              " 'profile_pic_url': None,\n",
              " 'background_cover_image_url': None,\n",
              " 'first_name': 'Faizal',\n",
              " 'last_name': 'Ahmed',\n",
              " 'full_name': 'Faizal Ahmed',\n",
              " 'follower_count': 719,\n",
              " 'occupation': 'Technical Lead at Finesse Global',\n",
              " 'headline': 'Technical Lead at Finess Global',\n",
              " 'summary': \"üåü Transforming Complexity into Clarity üåü\\n\\nAs a seasoned Integration Consultant and technical lead with over 16 years in IT, I bring a unique blend of strategy, innovation, and problem-solving skills to every project. I thrive at the intersection of business and technology, where I tackle challenges with a balanced approach, keeping both user experience and technical precision in mind.\\n\\nMy expertise spans  data analysis, project integration management,DevOps, and requirements analysis‚Äîskills I leverage to drive impactful solutions that align with business goals and streamline processes. I‚Äôm passionate about uncovering new insights in data and simplifying complex integrations to help teams and businesses grow.\\n\\nOutside of work, I'm an enthusiastic learner in the AI field, fascinated by its potential to transform industries. If you‚Äôre looking for someone with a proven track record in technology leadership, coupled with a genuine curiosity for emerging trends, let‚Äôs connect. Feel free to reach out for collaboration, insights, or just a great conversation about the future of tech!\",\n",
              " 'country': 'AE',\n",
              " 'country_full_name': 'United Arab Emirates',\n",
              " 'city': 'Dubai',\n",
              " 'state': None,\n",
              " 'experiences': [{'starts_at': {'day': 1, 'month': 11, 'year': 2021},\n",
              "   'ends_at': None,\n",
              "   'company': 'Finesse Global',\n",
              "   'company_linkedin_profile_url': 'https://www.linkedin.com/company/finesse-fz-llc',\n",
              "   'company_facebook_profile_url': None,\n",
              "   'title': 'Technical Lead',\n",
              "   'description': None,\n",
              "   'location': 'Dubai, United Arab Emirates',\n",
              "   'logo_url': 'https://s3.us-west-000.backblazeb2.com/proxycurl/company/finesse-fz-llc/profile?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=0004d7f56a0400b0000000001%2F20241109%2Fus-west-000%2Fs3%2Faws4_request&X-Amz-Date=20241109T113016Z&X-Amz-Expires=1800&X-Amz-SignedHeaders=host&X-Amz-Signature=762f919904d075e90621dbb7f78e312e2d7a29ca371ec1a7632687cfec26313e'},\n",
              "  {'starts_at': {'day': 1, 'month': 6, 'year': 2016},\n",
              "   'ends_at': {'day': 30, 'month': 11, 'year': 2021},\n",
              "   'company': 'EXCEED IT Services',\n",
              "   'company_linkedin_profile_url': 'https://www.linkedin.com/company/exceed-it-services',\n",
              "   'company_facebook_profile_url': None,\n",
              "   'title': 'Technology Support Professional',\n",
              "   'description': None,\n",
              "   'location': 'Dubai',\n",
              "   'logo_url': 'https://s3.us-west-000.backblazeb2.com/proxycurl/company/exceed-it-services/profile?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=0004d7f56a0400b0000000001%2F20241109%2Fus-west-000%2Fs3%2Faws4_request&X-Amz-Date=20241109T113016Z&X-Amz-Expires=1800&X-Amz-SignedHeaders=host&X-Amz-Signature=301393322b7439cfb656b12079bb18b275d9c381acc5e5ead0e0760959b3aac9'},\n",
              "  {'starts_at': {'day': 1, 'month': 12, 'year': 2014},\n",
              "   'ends_at': {'day': 30, 'month': 6, 'year': 2016},\n",
              "   'company': 'Raqmiyat',\n",
              "   'company_linkedin_profile_url': 'https://www.linkedin.com/company/raqmiyat',\n",
              "   'company_facebook_profile_url': None,\n",
              "   'title': 'Lead Consultant',\n",
              "   'description': None,\n",
              "   'location': 'Abudhabi',\n",
              "   'logo_url': 'https://s3.us-west-000.backblazeb2.com/proxycurl/company/raqmiyat/profile?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=0004d7f56a0400b0000000001%2F20241109%2Fus-west-000%2Fs3%2Faws4_request&X-Amz-Date=20241109T113016Z&X-Amz-Expires=1800&X-Amz-SignedHeaders=host&X-Amz-Signature=b152b78e066528196dca547d060819b61dbe96ceb8c3943bdaf8fea37d38dc3c'},\n",
              "  {'starts_at': {'day': 1, 'month': 6, 'year': 2012},\n",
              "   'ends_at': {'day': 31, 'month': 12, 'year': 2014},\n",
              "   'company': 'Supreme Group',\n",
              "   'company_linkedin_profile_url': 'https://www.linkedin.com/company/supreme-group',\n",
              "   'company_facebook_profile_url': None,\n",
              "   'title': 'Technical Consultant',\n",
              "   'description': None,\n",
              "   'location': None,\n",
              "   'logo_url': 'https://s3.us-west-000.backblazeb2.com/proxycurl/company/supreme-group/profile?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=0004d7f56a0400b0000000001%2F20241109%2Fus-west-000%2Fs3%2Faws4_request&X-Amz-Date=20241109T113016Z&X-Amz-Expires=1800&X-Amz-SignedHeaders=host&X-Amz-Signature=06ffc0850ec1bf9d2c20a8ef227cb4fd9e581a300ac683322c7cee4d62bcf5e0'},\n",
              "  {'starts_at': {'day': 1, 'month': 10, 'year': 2009},\n",
              "   'ends_at': {'day': 30, 'month': 6, 'year': 2012},\n",
              "   'company': 'Net Solutions Free Zone LLC',\n",
              "   'company_linkedin_profile_url': None,\n",
              "   'company_facebook_profile_url': None,\n",
              "   'title': 'Software Consultant',\n",
              "   'description': 'Developed several attendance modules for the Human resource application (HRNET).\\nDeveloped the sales application for the Merck Serono company.',\n",
              "   'location': 'Dubai,UAE',\n",
              "   'logo_url': None},\n",
              "  {'starts_at': {'day': 1, 'month': 10, 'year': 2007},\n",
              "   'ends_at': {'day': 30, 'month': 6, 'year': 2009},\n",
              "   'company': 'Polaris Financial Technology Limited',\n",
              "   'company_linkedin_profile_url': 'https://www.linkedin.com/company/polaris-financial-technologylimited',\n",
              "   'company_facebook_profile_url': None,\n",
              "   'title': 'Software Trainee',\n",
              "   'description': None,\n",
              "   'location': 'Chennai Area, India',\n",
              "   'logo_url': 'https://s3.us-west-000.backblazeb2.com/proxycurl/company/polaris-financial-technologylimited/profile?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=0004d7f56a0400b0000000001%2F20241109%2Fus-west-000%2Fs3%2Faws4_request&X-Amz-Date=20241109T113016Z&X-Amz-Expires=1800&X-Amz-SignedHeaders=host&X-Amz-Signature=d5a1137d06155733b48511bba527ef4b9c6c5469e54cfa001edf7d298cc2f123'}],\n",
              " 'education': [{'starts_at': {'day': 1, 'month': 1, 'year': 2002},\n",
              "   'ends_at': {'day': 31, 'month': 12, 'year': 2006},\n",
              "   'field_of_study': 'Computer Science',\n",
              "   'degree_name': 'Bachelor of Engineering (B.E.) in Computer Science',\n",
              "   'school': 'Arunai Engineering College',\n",
              "   'school_linkedin_profile_url': None,\n",
              "   'school_facebook_profile_url': None,\n",
              "   'description': None,\n",
              "   'logo_url': None,\n",
              "   'grade': None,\n",
              "   'activities_and_societies': None}],\n",
              " 'languages': [],\n",
              " 'languages_and_proficiencies': [],\n",
              " 'accomplishment_organisations': [],\n",
              " 'accomplishment_publications': [],\n",
              " 'accomplishment_honors_awards': [],\n",
              " 'accomplishment_patents': [],\n",
              " 'accomplishment_courses': [],\n",
              " 'accomplishment_projects': [],\n",
              " 'accomplishment_test_scores': [],\n",
              " 'volunteer_work': [],\n",
              " 'certifications': [{'starts_at': None,\n",
              "   'ends_at': None,\n",
              "   'name': 'Microsoft Certified Professional',\n",
              "   'license_number': 'E773-6113',\n",
              "   'display_source': None,\n",
              "   'authority': 'Microsoft',\n",
              "   'url': None},\n",
              "  {'starts_at': None,\n",
              "   'ends_at': None,\n",
              "   'name': 'Microsoft Specialist - Programming in C#',\n",
              "   'license_number': 'E773-6111',\n",
              "   'display_source': None,\n",
              "   'authority': 'Microsoft',\n",
              "   'url': None},\n",
              "  {'starts_at': {'day': 1, 'month': 9, 'year': 2014},\n",
              "   'ends_at': None,\n",
              "   'name': 'Oracle Certified Professional',\n",
              "   'license_number': None,\n",
              "   'display_source': None,\n",
              "   'authority': 'Oracle',\n",
              "   'url': None},\n",
              "  {'starts_at': {'day': 1, 'month': 5, 'year': 2014},\n",
              "   'ends_at': None,\n",
              "   'name': 'Oracle Database 11g Administrator Certified Associate',\n",
              "   'license_number': None,\n",
              "   'display_source': 'youracclaim.com',\n",
              "   'authority': 'Oracle',\n",
              "   'url': 'https://www.youracclaim.com/badges/78241bc2-6a22-4663-8e35-65ba15abde0b/linked_in_profile'},\n",
              "  {'starts_at': {'day': 1, 'month': 11, 'year': 2022},\n",
              "   'ends_at': {'day': 30, 'month': 11, 'year': 2025},\n",
              "   'name': 'Project Management Professional (PMP)¬Æ',\n",
              "   'license_number': '3374718',\n",
              "   'display_source': None,\n",
              "   'authority': 'Project Management Institute',\n",
              "   'url': None},\n",
              "  {'starts_at': {'day': 1, 'month': 11, 'year': 2022},\n",
              "   'ends_at': {'day': 30, 'month': 11, 'year': 2025},\n",
              "   'name': 'Project Management Professional (PMP)¬Æ',\n",
              "   'license_number': None,\n",
              "   'display_source': 'credly.com',\n",
              "   'authority': 'Project Management Institute',\n",
              "   'url': 'https://www.credly.com/badges/51428e64-ea98-478e-a45c-4162f4499dc9/linked_in_profile'}],\n",
              " 'connections': 662,\n",
              " 'people_also_viewed': [{'link': 'https://www.linkedin.com/in/shaher-tayfour?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAACueyu4BrYnhEzoK2jCY_uOyjr93dQTY0jo',\n",
              "   'name': 'Shaher Tayfour',\n",
              "   'summary': 'UAE Coding Ambassador ',\n",
              "   'location': None},\n",
              "  {'link': 'https://www.linkedin.com/in/meetarun?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAL7ttsBoFWn1FH2ZEJ9hba-gROgO2omg7I',\n",
              "   'name': 'Arun Kumar Madeswaran',\n",
              "   'summary': 'Data Scientist / Project Manager - Generative AI / Machine Learning | Big Data | AR/VR | Digital Transformation | AI Speaker',\n",
              "   'location': None},\n",
              "  {'link': 'https://www.linkedin.com/in/mohammedfazalullah?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAElDWwBdszvVZsJPQOLRuJfRqHqR4fji08',\n",
              "   'name': 'Mohammed Fazalullah ŸÖÿ≠ŸÖÿØ ŸÅÿ∂ŸÑ ÿßŸÑŸÑŸá',\n",
              "   'summary': 'Senior Developer Advocate at AWS | UAE Coding Ambassador | Builder | Community Mentor | Career Coach',\n",
              "   'location': None},\n",
              "  {'link': 'https://www.linkedin.com/in/omar-abdullah-474688202?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAADO2qJgB6INMctVKprplBdVj8vp6xdqIbyk',\n",
              "   'name': 'Omar Abdullah',\n",
              "   'summary': 'Driven Researcher | Tech Enthusiast | UX Learner',\n",
              "   'location': None},\n",
              "  {'link': 'https://www.linkedin.com/in/moyasser?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAG2ntoBn8_BFHuVJbgXi6Xye_E9wRvkC8g',\n",
              "   'name': 'Mohamed Yasser',\n",
              "   'summary': 'Government Solution Architect | Emerging Technology Advisor | Technology Analyst',\n",
              "   'location': None},\n",
              "  {'link': 'https://www.linkedin.com/in/payal-adhvaryu-a915b4a4?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAABYoWA0BsOOyyD11XibHESUv9-UXi0FdEOY',\n",
              "   'name': 'Payal Adhvaryu',\n",
              "   'summary': 'Assistant Manager -Talent Acquisition - Workforce planning  II Recruitment II  Team leadership II Lateral hiring I Executive Search II Stakeholder management',\n",
              "   'location': None},\n",
              "  {'link': 'https://www.linkedin.com/in/jakinsights?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAOpp1UBXKNfS-ZE1Tk59BoWU-8WMls7P2E',\n",
              "   'name': 'Arun kumar J',\n",
              "   'summary': 'Strategy Consultant (AI, Data, SaaS) | Product & Scalability Specialist |  Gen-AI Innovator | GTM Advisor | Client Partner',\n",
              "   'location': None},\n",
              "  {'link': 'https://www.linkedin.com/in/reshailnaeem?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAADGzhr8B3kHVpYo3u8PyWKdlSomvwaAAqyk',\n",
              "   'name': 'Reshail Naeem',\n",
              "   'summary': 'Machine Learning Engineer, occasional Data Scientist üë®üèª\\u200düíª | Operating at the Intersection of Insight and Code',\n",
              "   'location': None},\n",
              "  {'link': 'https://www.linkedin.com/in/paulsunil?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAHuutMBK7cDVeZO1FKD1n-WAwyPH_l_v1c',\n",
              "   'name': 'Sunil Paul',\n",
              "   'summary': 'Co-Founder & Managing Director at Finesse Global, 1CXO & Cyberhub | Founder & CEO at HomeyVillas.com',\n",
              "   'location': None},\n",
              "  {'link': 'https://www.linkedin.com/in/mhmddorgham?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAADwdfZoBg-eMcpGEZW2J6xTysSW_MCvNXMY',\n",
              "   'name': 'Mohamed Dorgham',\n",
              "   'summary': 'Software Engineer | Machine Learning Engineer | Assistant Instructor',\n",
              "   'location': None}],\n",
              " 'recommendations': ['Kannadasan Shyamsundar\\n\\n\\n\\nFaizal is a hard-working who knows how to get the job done quickly and effectively. He works well as a part of a team and can function as a leader when required. He has always exhibited superior communication skills and gets along well with staff and supervisors. He is highly respected by colleagues, customers and management.',\n",
              "  'Royer ...\\n\\n\\n\\nFaizal is an excellent Team Player, he is Technically Sound and has always come up with Great Solutions, no matter how Challenging the task is. He has demonstrated tremendous Flexibility while working with me on Mission Critical Projects. He has good R&D skills and hence is able to easily explore, learn and work on new technologies. I wish Faizal all the success for future assignments. '],\n",
              " 'activities': [],\n",
              " 'similarly_named_profiles': [],\n",
              " 'articles': [],\n",
              " 'groups': [{'profile_pic_url': 'https://media.licdn.com/dms/image/v2/D4D07AQHbWDHGKJ21Bw/group-logo_image-shrink_400x400/group-logo_image-shrink_400x400/0/1709610796434?e=1731474000&v=beta&t=sy1Wd7_PO_WxDUXSFAfIngQCRROVYstvAyrMEqO_ViU',\n",
              "   'name': 'CodersHQ UAE: Empowering Coders',\n",
              "   'url': 'https://www.linkedin.com/groups/8166391'},\n",
              "  {'profile_pic_url': 'https://media.licdn.com/dms/image/v2/D5607AQGBQteyAh9P0Q/group-logo_image-shrink_400x400/group-logo_image-shrink_400x400/0/1696415790931?e=1731474000&v=beta&t=pMUkx0f4lBkXAzWe7W3L5t1jIl9FhtfaivrFd2lZzI8',\n",
              "   'name': 'HOPE AI Premium Batch Students',\n",
              "   'url': 'https://www.linkedin.com/groups/14291017'}],\n",
              " 'skills': ['RESTful WebServices',\n",
              "  'Programming',\n",
              "  'Focal Point',\n",
              "  'Product Vision',\n",
              "  'Product Requirements',\n",
              "  'Specs',\n",
              "  'Quality Assurance',\n",
              "  'Technical Specs',\n",
              "  'Key Performance Indicators',\n",
              "  'Communication',\n",
              "  'Business Ownership',\n",
              "  'Supplier Evaluation',\n",
              "  'Representational State Transfer (REST)',\n",
              "  'SOAP',\n",
              "  'ASP.NET Core',\n",
              "  'Object-Oriented Programming (OOP)',\n",
              "  'ASP.NET MVC',\n",
              "  '.NET Core',\n",
              "  'Microsoft Azure',\n",
              "  'Amazon Web Services (AWS)',\n",
              "  'Research and Development (R&D)',\n",
              "  'Data Science',\n",
              "  'Artificial Intelligence (AI)',\n",
              "  'Python (Programming Language)',\n",
              "  'Microservices',\n",
              "  'Storage',\n",
              "  'SSRS',\n",
              "  'Microsoft SQL Server',\n",
              "  '.NET',\n",
              "  'ASP.NET',\n",
              "  'SDLC',\n",
              "  'C#',\n",
              "  'Web Services',\n",
              "  'Disaster Recovery',\n",
              "  'ADO.NET',\n",
              "  'Microsoft Technologies',\n",
              "  'Software Development',\n",
              "  'LINQ',\n",
              "  'Silverlight',\n",
              "  'Requirements Gathering',\n",
              "  'Integration',\n",
              "  'VB.NET',\n",
              "  'IIS',\n",
              "  'Software Project Management',\n",
              "  'ERP',\n",
              "  'SQL',\n",
              "  'DNS',\n",
              "  'Enterprise Resource Planning (ERP)',\n",
              "  'Software Development Life Cycle (SDLC)'],\n",
              " 'inferred_salary': None,\n",
              " 'gender': None,\n",
              " 'birth_date': None,\n",
              " 'industry': None,\n",
              " 'extra': None,\n",
              " 'interests': [],\n",
              " 'personal_emails': [],\n",
              " 'personal_numbers': []}"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "profile_data['headline']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "emtDMqmFADKB",
        "outputId": "e4079ffc-8b2a-4d45-c7f1-39edb63bd292"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Technical Lead at Finess Global'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Performance Testing to AI || Evolving into Machine Learning || Certified in Machine Learning and Artificial Intelligence || Leveraging AI and ML for Next-Gen Solutions"
      ],
      "metadata": {
        "id": "Cr2EIWxW7XIA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install gradio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eMZpBuuTBfca",
        "outputId": "5118caa8-ec1b-4c24-c05d-30a50f489a90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gradio\n",
            "  Downloading gradio-5.5.0-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Collecting fastapi<1.0,>=0.115.2 (from gradio)\n",
            "  Downloading fastapi-0.115.4-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.4.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting gradio-client==1.4.2 (from gradio)\n",
            "  Downloading gradio_client-1.4.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.27.2)\n",
            "Collecting huggingface-hub>=0.25.1 (from gradio)\n",
            "  Downloading huggingface_hub-0.26.2-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.4)\n",
            "Collecting markupsafe~=2.0 (from gradio)\n",
            "  Downloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.26.4)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.10.10)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (24.1)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (10.4.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.9.2)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart==0.0.12 (from gradio)\n",
            "  Downloading python_multipart-0.0.12-py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.2)\n",
            "Collecting ruff>=0.2.2 (from gradio)\n",
            "  Downloading ruff-0.7.3-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting safehttpx<1.0,>=0.1.1 (from gradio)\n",
            "  Downloading safehttpx-0.1.1-py3-none-any.whl.metadata (4.1 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
            "  Downloading starlette-0.41.2-py3-none-any.whl.metadata (6.0 kB)\n",
            "Collecting tomlkit==0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.12.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.12.5)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.12.2)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.32.0-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.4.2->gradio) (2024.10.0)\n",
            "Collecting websockets<13.0,>=10.0 (from gradio-client==1.4.2->gradio)\n",
            "  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (1.0.6)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.1->gradio) (3.16.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.1->gradio) (4.66.6)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (2.23.4)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.25.1->gradio) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.25.1->gradio) (2.2.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Downloading gradio-5.5.0-py3-none-any.whl (56.7 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m56.7/56.7 MB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.4.2-py3-none-any.whl (319 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m319.8/319.8 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_multipart-0.0.12-py3-none-any.whl (23 kB)\n",
            "Downloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
            "Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading fastapi-0.115.4-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m94.7/94.7 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading huggingface_hub-0.26.2-py3-none-any.whl (447 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m447.5/447.5 kB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
            "Downloading ruff-0.7.3-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.0 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m11.0/11.0 MB\u001b[0m \u001b[31m78.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safehttpx-0.1.1-py3-none-any.whl (8.4 kB)\n",
            "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading starlette-0.41.2-py3-none-any.whl (73 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m73.3/73.3 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvicorn-0.32.0-py3-none-any.whl (63 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m63.7/63.7 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpy-0.4.0-py3-none-any.whl (5.8 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pydub, websockets, uvicorn, tomlkit, semantic-version, ruff, python-multipart, markupsafe, ffmpy, aiofiles, starlette, huggingface-hub, safehttpx, gradio-client, fastapi, gradio\n",
            "  Attempting uninstall: markupsafe\n",
            "    Found existing installation: MarkupSafe 3.0.2\n",
            "    Uninstalling MarkupSafe-3.0.2:\n",
            "      Successfully uninstalled MarkupSafe-3.0.2\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface-hub 0.24.7\n",
            "    Uninstalling huggingface-hub-0.24.7:\n",
            "      Successfully uninstalled huggingface-hub-0.24.7\n",
            "Successfully installed aiofiles-23.2.1 fastapi-0.115.4 ffmpy-0.4.0 gradio-5.5.0 gradio-client-1.4.2 huggingface-hub-0.26.2 markupsafe-2.1.5 pydub-0.25.1 python-multipart-0.0.12 ruff-0.7.3 safehttpx-0.1.1 semantic-version-2.10.0 starlette-0.41.2 tomlkit-0.12.0 uvicorn-0.32.0 websockets-12.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import requests\n",
        "import os\n",
        "import json\n",
        "\n",
        "from groq import Groq\n",
        "\n",
        "client = Groq(api_key=\"enter your key\")\n",
        "\n",
        "\n",
        "\n",
        "class AutonomousEmailAgent:\n",
        "    def __init__(self, linkedin_url, company_name, role, word_limit, user_name, email, phone, linkedin):\n",
        "        self.linkedin_url = linkedin_url\n",
        "        self.company_name = company_name\n",
        "        self.role = role\n",
        "        self.word_limit = word_limit\n",
        "        self.user_name = user_name\n",
        "        self.email = email\n",
        "        self.phone = phone\n",
        "        self.linkedin = linkedin\n",
        "        self.bio = None\n",
        "        self.skills = []\n",
        "        self.experiences = []\n",
        "        self.company_info = None\n",
        "        self.role_description = None\n",
        "        self.attempts = 0\n",
        "\n",
        "    def fetch_linkedin_data(self):\n",
        "        proxycurl_api_key = os.getenv(\"PROXYCURL_API_KEY\")\n",
        "        if not self.linkedin_url:\n",
        "            print(\"Action: No LinkedIn URL provided, using default bio.\")\n",
        "            self.bio = \"A professional with diverse experience.\"\n",
        "            self.skills = [\"Adaptable\", \"Hardworking\"]\n",
        "            self.experiences = [\"Worked across various industries\"]\n",
        "        else:\n",
        "            print(\"Action: Fetching LinkedIn data via Proxycurl.\")\n",
        "            headers = {\"Authorization\": f\"Bearer {proxycurl_api_key}\"}\n",
        "            url = f\"https://nubela.co/proxycurl/api/v2/linkedin?url={self.linkedin_url}\"\n",
        "            response = requests.get(url, headers=headers)\n",
        "            if response.status_code == 200:\n",
        "                data = response.json()\n",
        "                self.bio = data.get(\"summary\", \"No bio available\")\n",
        "                self.skills = data.get(\"skills\", [])\n",
        "                self.experiences = data.get(\"experiences\", [])\n",
        "                print(\"LinkedIn data fetched successfully.\")\n",
        "            else:\n",
        "                print(\"Error: Unable to fetch LinkedIn profile. Status Code:\", response.status_code)\n",
        "                self.use_default_profile()\n",
        "\n",
        "    def use_default_profile(self):\n",
        "        print(\"Using default profile values.\")\n",
        "        self.bio = \"A professional with a versatile background and extensive experience.\"\n",
        "        self.skills = [\"Leadership\", \"Communication\", \"Problem-solving\"]\n",
        "        self.experiences = [{\"title\": \"Project Manager\"}, {\"title\": \"Team Leader\"}]\n",
        "\n",
        "    def run(self):\n",
        "        self.fetch_linkedin_data()\n",
        "        return self.autonomous_reasoning()\n",
        "\n",
        "    def autonomous_reasoning(self):\n",
        "        print(\"Autonomous Reasoning: Letting the LLM fully reason and act on available data...\")\n",
        "\n",
        "        reasoning_prompt = f\"\"\"\n",
        "        You are an AI agent tasked with generating a job application email using Simon Sinek's Start with Why model.\n",
        "        The email must begin with why the candidate is passionate about the role, then explain how their skills and\n",
        "        experience align with the company and role, and finally describe specific achievements that demonstrate their\n",
        "        capabilities. The email must not exceed {self.word_limit} words but should remain coherent and complete.\n",
        "        Here‚Äôs the current data:\n",
        "        - LinkedIn profile: {self.linkedin_url}\n",
        "        - Company Name: {self.company_name}\n",
        "        - Role: {self.role}\n",
        "        - Candidate's Bio: {self.bio}\n",
        "        - Candidate's Skills: {', '.join(self.skills)}\n",
        "        - Candidate's Experiences: {', '.join([exp['title'] for exp in self.experiences])}\n",
        "        Generate a fully coherent and complete email that fits within the word limit.\n",
        "        \"\"\"\n",
        "\n",
        "        return self.send_request_to_llm(reasoning_prompt)\n",
        "\n",
        "\n",
        "    def send_request_to_llm(self, prompt):\n",
        "        print(\"Sending request to Groq Cloud LLM...\")\n",
        "        api_key =\"your API key\"\n",
        "        if not api_key:\n",
        "            print(\"Error: API key not found. Please set the GROQ_API_KEY environment variable.\")\n",
        "            return \"Error: API key not found.\"\n",
        "\n",
        "        headers = {\n",
        "            \"Authorization\": f\"Bearer {api_key}\",\n",
        "            \"Content-Type\": \"application/json\"\n",
        "        }\n",
        "        data = {\n",
        "            \"model\": \"llama-3.1-70b-versatile\",\n",
        "            \"messages\": [{\"role\": \"user\", \"content\": prompt}]\n",
        "        }\n",
        "        response = requests.post(\"https://api.groq.com/openai/v1/chat/completions\", headers=headers, json=data)\n",
        "\n",
        "        print(f\"Status Code: {response.status_code}\")\n",
        "        if response.status_code == 200:\n",
        "            try:\n",
        "                result = response.json()\n",
        "                print(f\"LLM Response: {json.dumps(result, indent=2)}\")\n",
        "                choices = result.get(\"choices\", [])\n",
        "                if choices and \"message\" in choices[0]:\n",
        "                    content = choices[0][\"message\"][\"content\"]\n",
        "                    print(f\"Content: {content}\")\n",
        "                    return self.format_email(content)\n",
        "                else:\n",
        "                    print(\"Error: Unrecognized format in LLM response.\")\n",
        "                    return \"Error: Unrecognized response format.\"\n",
        "            except json.JSONDecodeError:\n",
        "                print(\"Error: Response from Groq Cloud LLM is not valid JSON.\")\n",
        "                return \"Error: Response is not in JSON format.\"\n",
        "        else:\n",
        "            print(f\"Error: Unable to connect to Groq Cloud LLM. Status Code: {response.status_code}\")\n",
        "            return \"Error: Unable to generate response.\"\n",
        "\n",
        "    def format_email(self, llm_response):\n",
        "        # Split the response into paragraphs for better formatting\n",
        "        paragraphs = [line.strip() for line in llm_response.split(\"\\n\") if line.strip()]\n",
        "        formatted_email = \"\\n\\n\".join(paragraphs)\n",
        "\n",
        "        # Add the closing section with a call to action\n",
        "        closing_section = (\n",
        "            \"\\n\\nI would appreciate the opportunity to discuss how my background, skills, and passion align with the goals \"\n",
        "            f\"of {self.company_name}. I am eager to contribute to your mission and support the development of future leaders.\\n\\n\"\n",
        "            \"Thank you for considering my application. I look forward to the possibility of discussing this role further.\\n\"\n",
        "        )\n",
        "\n",
        "        # Prepare the signature\n",
        "        signature = (\n",
        "            f\"Best regards,\\n\"\n",
        "            f\"{self.user_name}\\n\"\n",
        "            f\"Email: {self.email}\\n\"\n",
        "            f\"Phone: {self.phone}\\n\"\n",
        "            f\"LinkedIn: {self.linkedin}\"\n",
        "        )\n",
        "\n",
        "        # Ensure only one \"Best regards\" section and remove any duplicate signatures\n",
        "        if \"Best regards\" in formatted_email:\n",
        "            formatted_email = formatted_email.split(\"Best regards\")[0].strip()\n",
        "\n",
        "        return f\"{formatted_email}{closing_section}\\n{signature}\"\n",
        "\n",
        "# Gradio UI setup remains unchanged\n",
        "def gradio_ui():\n",
        "    name_input = gr.Textbox(label=\"Your Name\", placeholder=\"Enter your name\")\n",
        "    company_input = gr.Textbox(label=\"Company Name or URL\", placeholder=\"Enter the company name or website URL\")\n",
        "    role_input = gr.Textbox(label=\"Role Applying For\", placeholder=\"Enter the role you are applying for\")\n",
        "    email_input = gr.Textbox(label=\"Your Email Address\", placeholder=\"Enter your email address\")\n",
        "    phone_input = gr.Textbox(label=\"Your Phone Number\", placeholder=\"Enter your phone number\")\n",
        "    linkedin_input = gr.Textbox(label=\"Your LinkedIn URL\", placeholder=\"Enter your LinkedIn profile URL\")\n",
        "    word_limit_slider = gr.Slider(minimum=50, maximum=300, step=10, label=\"Email Word Limit\", value=150)\n",
        "\n",
        "    email_output = gr.Textbox(label=\"Generated Email\", placeholder=\"Your generated email will appear here\", lines=10)\n",
        "\n",
        "    def create_email(name, company_name, role, email, phone, linkedin_url, word_limit):\n",
        "        agent = AutonomousEmailAgent(linkedin_url, company_name, role, word_limit, name, email, phone, linkedin_url)\n",
        "        return agent.run()\n",
        "\n",
        "    demo = gr.Interface(\n",
        "        fn=create_email,\n",
        "        inputs=[name_input, company_input, role_input, email_input, phone_input, linkedin_input, word_limit_slider],\n",
        "        outputs=[email_output],\n",
        "        title=\"Email Writing AI Agent with ReAct\",\n",
        "        description=\"Generate a professional email for a job application using LinkedIn data, company info, and role description.\",\n",
        "        allow_flagging=\"never\"\n",
        "    )\n",
        "\n",
        "    demo.launch()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    gradio_ui()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 682
        },
        "id": "chuj7cVcBc05",
        "outputId": "374246f2-c5c0-4161-91ef-d67d9c7d77d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gradio/interface.py:399: UserWarning: The `allow_flagging` parameter in `Interface` is deprecated.Use `flagging_mode` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://79fdf45509fa019eee.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://79fdf45509fa019eee.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "uMxMAJTSBceB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import gradio as gr  # For creating the user interface\n",
        "import requests  # For making HTTP requests to external APIs\n",
        "import os  # For accessing environment variables\n",
        "import json  # For working with JSON data\n",
        "\n",
        "from groq import Groq  # For interacting with the Groq API\n",
        "\n",
        "# Initialize the Groq API client\n",
        "client = Groq(api_key=\"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\")\n",
        "\n",
        "# Class to manage the Autonomous Email Agent\n",
        "class AutonomousEmailAgent:\n",
        "    def __init__(self, linkedin_url, company_name, role, word_limit, user_name, email, phone, linkedin):\n",
        "        \"\"\"\n",
        "        Initialize the AutonomousEmailAgent with user details and placeholders for fetched data.\n",
        "        \"\"\"\n",
        "        self.linkedin_url = linkedin_url\n",
        "        self.company_name = company_name\n",
        "        self.role = role\n",
        "        self.word_limit = word_limit\n",
        "        self.user_name = user_name\n",
        "        self.email = email\n",
        "        self.phone = phone\n",
        "        self.linkedin = linkedin\n",
        "        # Placeholders for LinkedIn profile data\n",
        "        self.bio = None\n",
        "        self.skills = []\n",
        "        self.experiences = []\n",
        "        self.company_info = None\n",
        "        self.role_description = None\n",
        "        self.attempts = 0\n",
        "\n",
        "    def fetch_linkedin_data(self):\n",
        "        \"\"\"\n",
        "        Fetch LinkedIn profile data using the Proxycurl API.\n",
        "        \"\"\"\n",
        "        proxycurl_api_key = os.getenv(\"PROXYCURL_API_KEY\")  # Fetch API key from environment variables\n",
        "        if not self.linkedin_url:\n",
        "            # Use default data if no LinkedIn URL is provided\n",
        "            print(\"Action: No LinkedIn URL provided, using default bio.\")\n",
        "            self.bio = \"A professional with diverse experience.\"\n",
        "            self.skills = [\"Adaptable\", \"Hardworking\"]\n",
        "            self.experiences = [\"Worked across various industries\"]\n",
        "        else:\n",
        "            print(\"Action: Fetching LinkedIn data via Proxycurl.\")\n",
        "            headers = {\"Authorization\": f\"Bearer {proxycurl_api_key}\"}\n",
        "            url = f\"https://nubela.co/proxycurl/api/v2/linkedin?url={self.linkedin_url}\"\n",
        "            response = requests.get(url, headers=headers)\n",
        "            if response.status_code == 200:\n",
        "                # Successfully fetched data, update class attributes\n",
        "                data = response.json()\n",
        "                self.bio = data.get(\"summary\", \"No bio available\")\n",
        "                self.skills = data.get(\"skills\", [])\n",
        "                self.experiences = data.get(\"experiences\", [])\n",
        "                print(\"LinkedIn data fetched successfully.\")\n",
        "            else:\n",
        "                # Use default profile values in case of failure\n",
        "                print(\"Error: Unable to fetch LinkedIn profile. Status Code:\", response.status_code)\n",
        "                self.use_default_profile()\n",
        "\n",
        "    def use_default_profile(self):\n",
        "        \"\"\"\n",
        "        Use default values for profile data if fetching LinkedIn data fails.\n",
        "        \"\"\"\n",
        "        print(\"Using default profile values.\")\n",
        "        self.bio = \"A professional with a versatile background and extensive experience.\"\n",
        "        self.skills = [\"Leadership\", \"Communication\", \"Problem-solving\"]\n",
        "        self.experiences = [{\"title\": \"Project Manager\"}, {\"title\": \"Team Leader\"}]\n",
        "\n",
        "    def run(self):\n",
        "        \"\"\"\n",
        "        Execute the agent to fetch LinkedIn data and generate an email.\n",
        "        \"\"\"\n",
        "        self.fetch_linkedin_data()\n",
        "        return self.autonomous_reasoning()\n",
        "\n",
        "    def autonomous_reasoning(self):\n",
        "        \"\"\"\n",
        "        Generate a prompt for the LLM to create a professional email.\n",
        "        \"\"\"\n",
        "        print(\"Autonomous Reasoning: Letting the LLM fully reason and act on available data...\")\n",
        "\n",
        "        reasoning_prompt = f\"\"\"\n",
        "        You are an AI agent tasked with generating a job application email using Simon Sinek's Start with Why model.\n",
        "        The email must begin with why the candidate is passionate about the role, then explain how their skills and\n",
        "        experience align with the company and role, and finally describe specific achievements that demonstrate their\n",
        "        capabilities. The email must not exceed {self.word_limit} words but should remain coherent and complete.\n",
        "        Here‚Äôs the current data:\n",
        "        - LinkedIn profile: {self.linkedin_url}\n",
        "        - Company Name: {self.company_name}\n",
        "        - Role: {self.role}\n",
        "        - Candidate's Bio: {self.bio}\n",
        "        - Candidate's Skills: {', '.join(self.skills)}\n",
        "        - Candidate's Experiences: {', '.join([exp['title'] for exp in self.experiences])}\n",
        "        Generate a fully coherent and complete email that fits within the word limit.\n",
        "        \"\"\"\n",
        "\n",
        "        return self.send_request_to_llm(reasoning_prompt)\n",
        "\n",
        "    def send_request_to_llm(self, prompt):\n",
        "        \"\"\"\n",
        "        Send the generated prompt to the Groq API for processing.\n",
        "        \"\"\"\n",
        "        print(\"Sending request to Groq Cloud LLM...\")\n",
        "        api_key = \"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\"\n",
        "        if not api_key:\n",
        "            print(\"Error: API key not found. Please set the GROQ_API_KEY environment variable.\")\n",
        "            return \"Error: API key not found.\"\n",
        "\n",
        "        headers = {\n",
        "            \"Authorization\": f\"Bearer {api_key}\",\n",
        "            \"Content-Type\": \"application/json\"\n",
        "        }\n",
        "        data = {\n",
        "            \"model\": \"llama-3.1-70b-versatile\",\n",
        "            \"messages\": [{\"role\": \"user\", \"content\": prompt}]\n",
        "        }\n",
        "        response = requests.post(\"https://api.groq.com/openai/v1/chat/completions\", headers=headers, json=data)\n",
        "\n",
        "        print(f\"Status Code: {response.status_code}\")\n",
        "        if response.status_code == 200:\n",
        "            try:\n",
        "                # Parse and process the response\n",
        "                result = response.json()\n",
        "                print(f\"LLM Response: {json.dumps(result, indent=2)}\")\n",
        "                choices = result.get(\"choices\", [])\n",
        "                if choices and \"message\" in choices[0]:\n",
        "                    content = choices[0][\"message\"][\"content\"]\n",
        "                    print(f\"Content: {content}\")\n",
        "                    return self.format_email(content)\n",
        "                else:\n",
        "                    print(\"Error: Unrecognized format in LLM response.\")\n",
        "                    return \"Error: Unrecognized response format.\"\n",
        "            except json.JSONDecodeError:\n",
        "                print(\"Error: Response from Groq Cloud LLM is not valid JSON.\")\n",
        "                return \"Error: Response is not in JSON format.\"\n",
        "        else:\n",
        "            print(f\"Error: Unable to connect to Groq Cloud LLM. Status Code: {response.status_code}\")\n",
        "            return \"Error: Unable to generate response.\"\n",
        "\n",
        "    def format_email(self, llm_response):\n",
        "        \"\"\"\n",
        "        Format the LLM response into a professional email.\n",
        "        \"\"\"\n",
        "        # Split the response into paragraphs for readability\n",
        "        paragraphs = [line.strip() for line in llm_response.split(\"\\n\") if line.strip()]\n",
        "        formatted_email = \"\\n\\n\".join(paragraphs)\n",
        "\n",
        "        # Add a closing section to the email\n",
        "        closing_section = (\n",
        "            \"\\n\\nI would appreciate the opportunity to discuss how my background, skills, and passion align with the goals \"\n",
        "            f\"of {self.company_name}. I am eager to contribute to your mission and support the development of future leaders.\\n\\n\"\n",
        "            \"Thank you for considering my application. I look forward to the possibility of discussing this role further.\\n\"\n",
        "        )\n",
        "\n",
        "        # Add the user's signature\n",
        "        signature = (\n",
        "            f\"Best regards,\\n\"\n",
        "            f\"{self.user_name}\\n\"\n",
        "            f\"Email: {self.email}\\n\"\n",
        "            f\"Phone: {self.phone}\\n\"\n",
        "            f\"LinkedIn: {self.linkedin}\"\n",
        "        )\n",
        "\n",
        "        # Ensure there is no duplicate \"Best regards\" section\n",
        "        if \"Best regards\" in formatted_email:\n",
        "            formatted_email = formatted_email.split(\"Best regards\")[0].strip()\n",
        "\n",
        "        return f\"{formatted_email}{closing_section}\\n{signature}\"\n",
        "\n",
        "# Gradio UI setup\n",
        "def gradio_ui():\n",
        "    \"\"\"\n",
        "    Set up the Gradio user interface for the email generator.\n",
        "    \"\"\"\n",
        "    # Input fields\n",
        "    name_input = gr.Textbox(label=\"Your Name\", placeholder=\"Enter your name\")\n",
        "    company_input = gr.Textbox(label=\"Company Name or URL\", placeholder=\"Enter the company name or website URL\")\n",
        "    role_input = gr.Textbox(label=\"Role Applying For\", placeholder=\"Enter the role you are applying for\")\n",
        "    email_input = gr.Textbox(label=\"Your Email Address\", placeholder=\"Enter your email address\")\n",
        "    phone_input = gr.Textbox(label=\"Your Phone Number\", placeholder=\"Enter your phone number\")\n",
        "    linkedin_input = gr.Textbox(label=\"Your LinkedIn URL\", placeholder=\"Enter your LinkedIn profile URL\")\n",
        "    word_limit_slider = gr.Slider(minimum=50, maximum=300, step=10, label=\"Email Word Limit\", value=150)\n",
        "\n",
        "    # Output field\n",
        "    email_output = gr.Textbox(label=\"Generated Email\", placeholder=\"Your generated email will appear here\", lines=10)\n",
        "\n",
        "    # Function to create the email\n",
        "    def create_email(name, company_name, role, email, phone, linkedin_url, word_limit):\n",
        "        agent = AutonomousEmailAgent(linkedin_url, company_name, role, word_limit, name, email, phone, linkedin_url)\n",
        "        return agent.run()\n",
        "\n",
        "    # Build and launch the Gradio interface\n",
        "    demo = gr.Interface(\n",
        "        fn=create_email,\n",
        "        inputs=[name_input, company\n"
      ],
      "metadata": {
        "id": "ko-ZBKqsEG0V"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
